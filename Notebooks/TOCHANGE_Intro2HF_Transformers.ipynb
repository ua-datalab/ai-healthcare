{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a188293a-305b-4bf0-8faa-108bc53ecb32",
   "metadata": {},
   "source": [
    "## Using Hugging Face Transformers\n",
    "\n",
    "Updated 06/12/2024 C. Liz√°rraga, UArizona DataLab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07daf5f4-b486-460e-9497-95f687141d38",
   "metadata": {},
   "source": [
    "**Install required libraries**\n",
    "\n",
    "Hugging Face Libraries are built on top of frameworks as PyTorch, TensorFlow and JAX.\n",
    "For this case we will import _PyTorch_.\n",
    "\n",
    "**To execute code Notebook cells:** Press _SHIFT+ENTER_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe207814-a7ba-44c7-9d54-448d6e885abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch\n",
    "!pip install -q transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f5617b-9c41-4265-9c80-c87c37a31142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import specific classes from Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b51ee-cb25-465f-8a06-e7cbfc70c4cf",
   "metadata": {},
   "source": [
    "## Phi-2, an instruction model \n",
    "Defining the model to run. Will use Microsoft's Phi-2.\n",
    "If you are looking for a model that can answer questions, Phi-2.0 is a great model.\n",
    "It will download the model from Huging Face locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfdb84a-c6d2-4902-9f1e-e8c0f1e3a8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396a5778794344a2bfa0f44aa137a39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46a063431644d7e8a7eb17eb47f74ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e157b17436cc40da8b194d604f37aacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbd60d81a5e4d5eb4fb1eef78bf74f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4da6af0cd4747d1a2533231061834a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831939a8b1854d4aac1602e690eb1f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f438fe969786429ead68ec804f50bc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"microsoft/phi-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99937c62-cb0e-492b-95ca-7f4524e88c29",
   "metadata": {},
   "source": [
    "Next, create a tokenizer object and load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0c4c30-ae61-4e55-9a9d-410804baae30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c00978c86f84d0f86c98b01206d008b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52138e3dd02244ba93f255d87ca4199d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6f3afc854447559d1f46dd142bff90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bb985e927b4effb7b08b8a0da89852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1516a285944e99997a0a8736b0fbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a9a4527db9462c9f077d64ffa55e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True, padding_side='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3119718-09cb-4b4c-bad2-70e8d4cdf959",
   "metadata": {},
   "source": [
    "**Create the inputs for the model to process**\n",
    "We pose a question to the model, and it will answer accordingly from the text corpus the model was instructed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7cd2e8-2bba-4504-988c-7306f9ead068",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Please tell me, who are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936457c-2c02-4bbd-a27b-fa5904b0a86f",
   "metadata": {},
   "source": [
    "**Run generation and decode the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24055e11-d6a9-4d66-8871-07e3ea29b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please tell me, who are you?\n",
      "\n",
      "The man smiled and said, \"I am a traveler, and I have come to this village to learn about the culture and traditions of the people here. I have heard that you are the best person to show me around.\"\n",
      "\n",
      "Lily was thrilled to have a new friend, and she eagerly showed the man around the village. She took him to the market, where he saw the colorful fruits and vegetables, and the handmade crafts that the villagers sold. She took him to the temple\n"
     ]
    }
   ],
   "source": [
    "eos_token_id=50256\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "outputs = model.generate(input_ids[\"input_ids\"], max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "decoded_outputs = tokenizer.decode(outputs[0])\n",
    "print(decoded_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61095b7f-1a49-416a-9acf-a0c7bdbc62b9",
   "metadata": {},
   "source": [
    "**Let's try another QA example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "112a64f8-e746-44ba-b73d-c8dc9e9e1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Please write a detailed analogy between mathematics and a lighthouse.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c051e1d-8905-42a9-b29f-275e152917d8",
   "metadata": {},
   "source": [
    "**Run generation and decode the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07b5e4a-1bac-4580-ad8b-2941e9823839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a detailed analogy between mathematics and a lighthouse.\n",
      "\n",
      "Answer: Mathematics is like a lighthouse because it provides guidance and direction. Just as a lighthouse helps ships navigate through treacherous waters, mathematics helps us navigate through complex problems and find solutions. It illuminates the path ahead, allowing us to make informed decisions and avoid getting lost in the darkness of uncertainty.\n",
      "\n",
      "Exercise 2:\n",
      "Compare and contrast the role of logic in mathematics and the role of a compass in navigation.\n",
      "\n",
      "Answer: Logic in mathematics is like a compass in navigation\n"
     ]
    }
   ],
   "source": [
    "eos_token_id=50256\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "outputs = model.generate(input_ids[\"input_ids\"], max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "decoded_outputs = tokenizer.decode(outputs[0])\n",
    "print(decoded_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4b75d-e76b-4fbd-a80c-9374d1215093",
   "metadata": {},
   "source": [
    "## Now, try a different transformer for sentiment analysis \n",
    "\n",
    "We will use the DistilBERT base multilingual (cased). This model is cased: it does make a difference between english and English.\n",
    "\n",
    "This Transformer-based language model is trained on the concatenation of Wikipedia in 104 different languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7719ffe4-0afa-4fe1-a0bf-081913d61f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820976fd23d5451882d5fd2fbaaa2b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa8d7b26363446385b0857b57463edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c317540073439ab5a9cb3b1b67937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c0400d808f4b03b964e628e8f7271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d5776-7bd6-4db9-97fc-aba35e927d3d",
   "metadata": {},
   "source": [
    "**Pre-process text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5121cb46-e85d-4f5e-8235-dab1a886e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love programming!\"\n",
    "tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b6fcc-b1ec-4303-bd4c-ff88fb03a79d",
   "metadata": {},
   "source": [
    "**Model Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7cef555-dbc7-4333-afb5-009aec71416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a5223-80b3-4e7b-8b66-c558d882fef8",
   "metadata": {},
   "source": [
    "**Interpret results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "122eb185-9518-4638-b188-d6b3bc62267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is: Positive\n"
     ]
    }
   ],
   "source": [
    "label_ids = torch.argmax(probabilities, dim=1)\n",
    "labels = ['Negative', 'Positive']\n",
    "label = labels[label_ids]\n",
    "print(f\"The sentiment is: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30de477-fb07-41ed-b3e7-0436f2febb5c",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "The pipeline is the easiest way to use a pretrained model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d286fda3-2d52-4a06-bf35-28b7902dd759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a042831080f4400b42c20d099b34bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d415751931430d81237f5983444910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98fd5ebcb7408abd6405f87642c1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfc010063e94f49beca7466685a063e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb7cc9e1ae048f4b4cfb1eaded9f0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-multilingual-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79aeabfe-5e99-4999-848d-3d00289e717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5270528793334961}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I hate this book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cdfb652-be1e-4b2d-a56b-10d87cfba456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5238034129142761}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I love this book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c45e7-96c3-42cf-87cd-af2564d1e267",
   "metadata": {},
   "source": [
    "**We need a pre-trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20f1feb5-594e-4970-81ce-b959aa1142c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "distilled_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "553acfcb-b1f4-4057-ad9c-b17436967f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.9731044769287109},\n",
       "  {'label': 'neutral', 'score': 0.016910091042518616},\n",
       "  {'label': 'negative', 'score': 0.00998548325151205}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english\n",
    "distilled_sentiment_classifier (\"I love this movie and i would watch it again and again!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bdbbcf0-23ca-4c45-96c4-45a3c267186c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.9293941259384155},\n",
       "  {'label': 'neutral', 'score': 0.04148319736123085},\n",
       "  {'label': 'negative', 'score': 0.029122695326805115}]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spanish\n",
    "distilled_sentiment_classifier (\"Me encanta esta pel√≠cula y la ver√≠a una y otra vez\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e9445dc-4e8a-4d15-a43a-336178c4f9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.8528407216072083},\n",
       "  {'label': 'neutral', 'score': 0.0751723051071167},\n",
       "  {'label': 'negative', 'score': 0.07198696583509445}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# french\n",
    "distilled_sentiment_classifier (\"J'adore ce film et je le regarderais encore et encore!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd27ab-1bb7-46a6-88ac-9c99177123ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='distilbert-base-multilingual-cased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b9c2b-1170-492b-bbbe-a63feafb9e21",
   "metadata": {},
   "source": [
    "**Use the classifier on a target text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ec1178e-722a-43e3-9df7-a40fdfbd6a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.9666252732276917},\n",
       "  {'label': 'neutral', 'score': 0.020221391692757607},\n",
       "  {'label': 'negative', 'score': 0.013153337873518467}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilled_sentiment_classifier(\"We are very happy to show you the ü§ó Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a5a52-852d-4563-94cc-f6ee1aebf590",
   "metadata": {},
   "source": [
    "## Another example: Use of BERT model and tokenizer in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dfecec8-530b-4276-a57f-07fea7580fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62d27345-ce6f-4c52-817c-c7ab60d90ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d6f66a4ebd4afaa0effab6eb2e6a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b5d6d49599431f834dc58c16e1f87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985db499781440bea93e6618bbd59bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde6da5acd2d42b7b61011c4c2617708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4d22d6ce32459eab27a9c0d051e450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13f20ab1-147e-4dd0-a5bf-0de8555c7fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7272651791572571}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e426dcd0-3fdc-473b-bc8a-c132d9397935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the ü§ó Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df29f9d-8a5e-477a-991f-6c52c7c25947",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
