{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Sequence Modeling with PyTorch + ClinicalBERT\n",
    "### Predict ICU Stay Length based on lab results using ClinicalBERT\n",
    "\n",
    "Updated 09/27/2024 G. Chism, U of A InfoSci + DataLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required libraries\n",
    "\n",
    "For this case we will import _PyTorch_, _sklearn_, _pandas_, and _numpy_.\n",
    "\n",
    "**To execute code Notebook cells:** Press _SHIFT+ENTER_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q torch\n",
    "#!pip install -q scikit-learn\n",
    "#!pip install -q pandas\n",
    "#!pip install -q numpy\n",
    "#!pip install watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best practice to have all of the libraries loaded at the top of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import specific classes from PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW\n",
    "\n",
    "# Import preprocessing from Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have GPUs available (hint, we won't...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing:\n",
    "\n",
    "### Converting Data Types:\n",
    "\n",
    "`pd.to_numeric()` converts columns like los and valuenum to numeric types, coercing any errors (e.g., invalid strings) to NaN.\n",
    "`pd.to_datetime()` ensures that the charttime and dob columns are properly treated as datetime objects for time-series modeling.\n",
    "\n",
    "### Handling Missing Values:\n",
    "\n",
    "After converting the data types, we check for missing values and handle them (in this case, dropping rows with missing values in critical columns like `los` and `valuenum`).\n",
    "\n",
    "\n",
    "### Check Data Info and Head:\n",
    "\n",
    "This ensures that the data is now clean and ready for modeling, with no incorrect data types or missing values in critical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29981 entries, 0 to 29986\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   subject_id  29981 non-null  object\n",
      " 1   icustay_id  29981 non-null  object\n",
      " 2   los         29981 non-null  object\n",
      " 3   itemid      29981 non-null  object\n",
      " 4   charttime   29981 non-null  object\n",
      " 5   value       29981 non-null  object\n",
      " 6   valuenum    29981 non-null  object\n",
      " 7   valueuom    29981 non-null  object\n",
      " 8   gender      29981 non-null  object\n",
      " 9   dob         29981 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 2.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming the data is already preprocessed via mimic-iii-demo-subset.py and saved as mimic_data.csv\n",
    "mimic_data = pd.read_csv('data/mimic_data.csv')\n",
    "\n",
    "# Handle missing values (example: drop rows with missing valuenum or los)\n",
    "clean_data = mimic_data.dropna(subset=['los', 'valuenum'])\n",
    "\n",
    "print(clean_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Data by Patients and Time\n",
    "Sort the data by patient and charttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.sort_values(['subject_id', 'charttime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset Suitable for ClinicalBERT\n",
    "\n",
    "- Convert numerical lab values to a string that ClinicalBERT can use as input. (Already okay) \n",
    "\n",
    "- Each patientâ€™s lab values are concatenated into a single text, simulating a clinical note."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
