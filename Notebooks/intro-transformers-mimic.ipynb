{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Sequence Modeling with PyTorch + ClinicalBERT\n",
    "### Predict ICU Stay Length based on lab results using ClinicalBERT\n",
    "\n",
    "Updated 09/27/2024 G. Chism, U of A InfoSci + DataLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required libraries\n",
    "\n",
    "For this case we will import _PyTorch_, _sklearn_, _pandas_, and _numpy_.\n",
    "\n",
    "**To execute code Notebook cells:** Press _SHIFT+ENTER_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install -q torch\n",
    "#%pip install -q scikit-learn\n",
    "#%pip install -q pandas\n",
    "#%pip install -q numpy\n",
    "#%pip install watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best practice to have all of the libraries loaded at the top of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/61/5w0zfjkx2ks_c31ggc0f8gch0000gt/T/ipykernel_63835/222605643.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/gchism/Library/r-miniconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import specific classes from PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW\n",
    "\n",
    "# Import preprocessing from Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have GPUs available (hint, we won't...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing:\n",
    "\n",
    "### Converting Data Types:\n",
    "\n",
    "`pd.to_numeric()` converts columns like los and valuenum to numeric types, coercing any errors (e.g., invalid strings) to NaN.\n",
    "`pd.to_datetime()` ensures that the charttime and dob columns are properly treated as datetime objects for time-series modeling.\n",
    "\n",
    "### Handling Missing Values:\n",
    "\n",
    "After converting the data types, we check for missing values and handle them (in this case, dropping rows with missing values in critical columns like `los` and `valuenum`).\n",
    "\n",
    "\n",
    "### Check Data Info and Head:\n",
    "\n",
    "This ensures that the data is now clean and ready for modeling, with no incorrect data types or missing values in critical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id icustay_id       los itemid            charttime value valuenum  \\\n",
      "0      10006     206504  0.043246  50912  2164-09-24 20:21:00   7.0      7.0   \n",
      "1      10006     206504  0.043246  50931  2164-09-24 20:21:00   126    126.0   \n",
      "2      10006     206504  0.043246  51222  2164-09-24 20:21:00  11.2     11.2   \n",
      "3      10006     206504  0.043246  50912  2164-09-25 05:25:00   7.4      7.4   \n",
      "4      10006     206504  0.043246  50931  2164-09-25 05:25:00   106    106.0   \n",
      "\n",
      "  valueuom gender                  dob  \n",
      "0    mg/dL      F  2094-03-05 00:00:00  \n",
      "1    mg/dL      F  2094-03-05 00:00:00  \n",
      "2     g/dL      F  2094-03-05 00:00:00  \n",
      "3    mg/dL      F  2094-03-05 00:00:00  \n",
      "4    mg/dL      F  2094-03-05 00:00:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/5w0zfjkx2ks_c31ggc0f8gch0000gt/T/ipykernel_63835/3444407880.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['los'] = np.float64(clean_data['los'])\n",
      "/var/folders/61/5w0zfjkx2ks_c31ggc0f8gch0000gt/T/ipykernel_63835/3444407880.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['los'] = scaler.fit_transform(clean_data[['los']])\n"
     ]
    }
   ],
   "source": [
    "# Assuming the data is already preprocessed via mimic-iii-demo-subset.py and saved as mimic_data.csv\n",
    "mimic_data = pd.read_csv('data/mimic_data.csv')\n",
    "\n",
    "mimic_data['los'] = pd.to_numeric(mimic_data['los'], errors='coerce')\n",
    "\n",
    "# Handle missing values (example: drop rows with missing valuenum or los)\n",
    "clean_data = mimic_data.dropna(subset=['los', 'valuenum'])\n",
    "\n",
    "# Convert los to float64\n",
    "clean_data['los'] = np.float64(clean_data['los'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "clean_data['los'] = scaler.fit_transform(clean_data[['los']])\n",
    "\n",
    "print(clean_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Data by Patients and Time\n",
    "Sort the data by patient and charttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/5w0zfjkx2ks_c31ggc0f8gch0000gt/T/ipykernel_63835/567539065.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data.sort_values(['subject_id', 'charttime'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "clean_data.sort_values(['subject_id', 'charttime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset Suitable for ClinicalBERT\n",
    "\n",
    "- Convert numerical lab values to a string that ClinicalBERT can use as input. (Already okay) \n",
    "\n",
    "- Each patient’s lab values are concatenated into a single text, simulating a clinical note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lab values for each patient to simulate a clinical note\n",
    "def create_text_representation(df):\n",
    "    df['text'] = df.groupby('subject_id')['valuenum'].transform(lambda x: ' '.join(map(str, x)))\n",
    "    df = df.drop_duplicates(subset=['subject_id'])\n",
    "    return df[['subject_id', 'text', 'los']]\n",
    "\n",
    "# Apply the transformation\n",
    "data_for_clinicalbert = create_text_representation(mimic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tokenizer and Dataset for ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "\n",
    "class ClinicalBERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels.astype(float)\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = max_len \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = float(self.labels[item])  \n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "    \n",
    "# Create Dataset and DataLoader\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset = ClinicalBERTDataset(\n",
    "    texts=data_for_clinicalbert['text'].to_numpy(),\n",
    "    labels=data_for_clinicalbert['los'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ClinicalBERT Model for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', num_labels=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Optimizer and Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN loss detected\n",
      "Epoch 1/5, Loss: 45.3497\n",
      "NaN loss detected\n",
      "Epoch 2/5, Loss: 33.2112\n",
      "NaN loss detected\n",
      "Epoch 3/5, Loss: 28.5100\n",
      "NaN loss detected\n",
      "Epoch 4/5, Loss: 36.8177\n",
      "NaN loss detected\n",
      "Epoch 5/5, Loss: 28.8239\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits.squeeze(), labels)  # Squeeze to match shape\n",
    "        \n",
    "        if torch.isnan(loss):  # Check for NaN loss\n",
    "            print(\"NaN loss detected\")\n",
    "            continue\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "    avg_train_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Loss: {avg_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.44\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = outputs.logits.squeeze().cpu().tolist()\n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(labels.cpu().tolist())\n",
    "\n",
    "# Check for NaN values in predictions and actuals\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Remove NaN values from predictions and actuals\n",
    "mask = ~np.isnan(predictions) & ~np.isnan(actuals)  # Only keep non-NaN values\n",
    "predictions = predictions[mask]\n",
    "actuals = actuals[mask]\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
